{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Analysis and Machine Learning Workflow for CsPbCl3 Quantum Dots**\n",
    "\n",
    "This project analyzes and models data related to CsPbCl3 quantum dots using statistical and machine learning techniques. The workflow includes data visualization, correlation analysis, and predictive modeling using Random Forest regression. Below are the key steps and explanations.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Data Loading and Preprocessing**\n",
    "\n",
    "The dataset is loaded from two Excel files:\n",
    "1. `CsPbCl3_QDs.xlsx`: Original dataset.\n",
    "2. `modified_data.xlsx`: Preprocessed dataset.\n",
    "\n",
    "### Key Steps:\n",
    "- **Categorical Encoding**: Categorical columns are encoded using one-hot encoding.\n",
    "- **Feature Selection**: Relevant features and outputs are selected for analysis.\n",
    "- **Handling Missing Values**: Missing values are imputed with column means during modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Data Visualization**\n",
    "\n",
    "### **Histograms**\n",
    "Histograms display the distribution of key output variables (`size_nm`, `S_abs_nm_Y1`, `PL`).\n",
    "\n",
    "- **Purpose**: Understand the spread and skewness of the data.\n",
    "- **Colors**: Different colors represent each variable for better readability.\n",
    "\n",
    "### **Boxplots**\n",
    "Boxplots provide insights into the variability and presence of outliers in the data.\n",
    "\n",
    "- **Purpose**: Detect outliers and compare data distributions for key variables.\n",
    "- **Customization**: Bold labels and color-coded boxes enhance visualization.\n",
    "\n",
    "### **Pearson Correlation Heatmap**\n",
    "A heatmap is used to visualize the correlation between input features (`Cl_mmol`, `Cs_mmol`, `Oleylamine_OLA_ml`, etc.) and outputs (`size_nm`, `S_abs_nm_Y1`, `PL`).\n",
    "\n",
    "- **Purpose**: Identify relationships between features and outputs.\n",
    "- **Customization**: Includes custom labels and color gradients for better interpretability.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Machine Learning: Random Forest Regression**\n",
    "\n",
    "Random Forest regression is applied to predict the output variables (`size_nm`, `S_abs_nm_Y1`, `PL`).\n",
    "\n",
    "### Key Steps:\n",
    "- **Data Splitting**: The dataset is split into training (70%) and testing (30%) sets.\n",
    "- **Hyperparameter Tuning**: Grid search is used to find the optimal `max_features`.\n",
    "- **Evaluation Metrics**:\n",
    "  - **R² (Coefficient of Determination)**: Explains the variance in the target variable.\n",
    "  - **RMSE (Root Mean Squared Error)**: Measures prediction error.\n",
    "  - **MAE (Mean Absolute Error)**: Captures the average magnitude of prediction errors.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Results Visualization**\n",
    "\n",
    "### **Observed vs Predicted Values**\n",
    "Scatter plots compare observed and predicted values for each target variable (`size_nm`, `S_abs_nm_Y1`, `PL`).\n",
    "\n",
    "- **Purpose**: Assess the alignment of predictions with actual values.\n",
    "- **Customization**: Separate plots for each variable with labeled axes and legends.\n",
    "\n",
    "### **Residual Analysis**\n",
    "Residual plots and histograms show the distribution of prediction errors.\n",
    "\n",
    "- **Purpose**: Identify any patterns or biases in prediction errors.\n",
    "- **Customization**: Includes kernel density estimation (KDE) for better visualization.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "This analysis provides insights into the relationships between input features and output variables in CsPbCl3 quantum dots. The Random Forest model demonstrates its effectiveness in predicting key properties. Visualization aids in interpreting the model's performance and the data's characteristics.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# File Paths\n",
    "file_path_original = \"./CsPbCl3_QDs.xlsx\"\n",
    "file_path_modified = \"./modified_data.xlsx\"\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the dataset and preprocess it for analysis.\n",
    "    \"\"\"\n",
    "    data = pd.read_excel(file_path)\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Apply one-hot encoding\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = one_hot_encoder.fit_transform(data[categorical_columns])\n",
    "    one_hot_encoded_df = pd.DataFrame(\n",
    "        one_hot_encoded, \n",
    "        columns=one_hot_encoder.get_feature_names_out(categorical_columns)\n",
    "    )\n",
    "    \n",
    "    # Replace categorical columns with one-hot encoded columns\n",
    "    data_encoded = data.drop(categorical_columns, axis=1)\n",
    "    data_encoded = pd.concat([data_encoded, one_hot_encoded_df], axis=1)\n",
    "    \n",
    "    return data_encoded\n",
    "\n",
    "# Load datasets\n",
    "data_original = load_and_preprocess_data(file_path_original)\n",
    "data_modified = load_and_preprocess_data(file_path_modified)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Visualization\n",
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for histograms\n",
    "columns = ['size_nm', 'S_abs_nm_Y1', 'PL']\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# Plot histograms\n",
    "fig, axs = plt.subplots(1, 3, figsize=(13, 5))\n",
    "for ax, column, color in zip(axs, columns, colors):\n",
    "    ax.hist(data_modified[column], bins=20, color=color, alpha=0.7)\n",
    "    ax.set_title(f'Distribution of {column}', fontsize=12)\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot visualization\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 6))\n",
    "custom_labels = ['Size', '1 S abs', 'PL']\n",
    "\n",
    "for ax, column, color in zip(axs, columns, colors):\n",
    "    ax.boxplot(data_modified[column], patch_artist=True, boxprops=dict(facecolor=color))\n",
    "    ax.set_title(f'Boxplot of {column}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(custom_labels[columns.index(column)], fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Value', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature matrix and outputs\n",
    "FeatureMatrix = ['Cl_mmol', 'Cs_mmol', 'Oleylamine_OLA_ml', 'Oleicacid_OA_ml', 'Temperature']\n",
    "Output = ['size_nm', 'S_abs_nm_Y1', 'PL']\n",
    "\n",
    "# Select relevant columns\n",
    "df_corr = data_modified[FeatureMatrix + Output]\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "cor = df_corr.corr()\n",
    "\n",
    "# Define custom labels\n",
    "custom_labels = ['Cl amount', 'Cs amount', 'OLA volume', 'OA volume', 'Temperature', 'Size', '1 S abs', 'PL']\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cor, annot=True, cmap='coolwarm', mask=np.triu(cor), xticklabels=custom_labels, yticklabels=custom_labels)\n",
    "plt.title('Pearson Correlation Heatmap', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning: Random Forest\n",
    "def train_random_forest(data, target):\n",
    "    \"\"\"\n",
    "    Train a Random Forest model for a given target.\n",
    "    \"\"\"\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Fill missing values\n",
    "    X_train_filled = X_train.fillna(X_train.mean())\n",
    "    X_test_filled = X_test.fillna(X_train.mean())\n",
    "    y_train_filled = y_train.fillna(y_train.mean())\n",
    "    \n",
    "    # Random Forest with Grid Search\n",
    "    param_grid = {'max_features': [3, 5, 7, 9, 11, 13, 15]}\n",
    "    rf_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=RepeatedKFold(n_splits=5, n_repeats=3), verbose=1)\n",
    "    grid_search.fit(X_train_filled, y_train_filled)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    predictions_train = grid_search.predict(X_train_filled)\n",
    "    predictions_test = grid_search.predict(X_test_filled)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Train R2\": r2_score(y_train, predictions_train),\n",
    "        \"Test R2\": r2_score(y_test, predictions_test),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train, predictions_train)),\n",
    "        \"Test RMSE\": np.sqrt(mean_squared_error(y_test, predictions_test)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, predictions_train),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, predictions_test)\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions_test, y_test\n",
    "\n",
    "# Evaluate targets\n",
    "targets = ['size_nm', 'S_abs_nm_Y1', 'PL']\n",
    "results = {}\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"Training for target: {target}\")\n",
    "    metrics, predictions, actuals = train_random_forest(data_modified, target)\n",
    "    results[target] = {\"metrics\": metrics, \"predictions\": predictions, \"actuals\": actuals}\n",
    "    print(f\"Metrics for {target}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "titles = ['Size', '1 S abs', 'PL']\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    predictions = results[target]['predictions']\n",
    "    actuals = results[target]['actuals']\n",
    "    \n",
    "    # Plot (a): Observed vs Predicted\n",
    "    sns.scatterplot(x=np.arange(len(actuals)), y=actuals, ax=axs[i, 0], label='Observed', color='red')\n",
    "    sns.scatterplot(x=np.arange(len(predictions)), y=predictions, ax=axs[i, 0], label='Predicted', color='blue')\n",
    "    axs[i, 0].set_title(f'{titles[i]} - Observed vs Predicted')\n",
    "    \n",
    "    # Plot (b): Residuals\n",
    "    residuals = actuals - predictions\n",
    "    sns.histplot(residuals, ax=axs[i, 1], kde=True, color='green')\n",
    "    axs[i, 1].set_title(f'{titles[i]} - Residuals Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
