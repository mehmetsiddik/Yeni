{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model for Performance Evaluation\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This script evaluates the performance of a Decision Tree Regressor on three target variables (`size_nm`, `S_abs_nm_Y1`, and `PL`) using a dataset of quantum dot features. The following steps were performed:\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - Handled missing values by imputing the median.\n",
    "   - Scaled features using Min-Max Scaling.\n",
    "   - Applied one-hot encoding to categorical variables for machine learning compatibility.\n",
    "\n",
    "2. **Model Training and Hyperparameter Tuning**:\n",
    "   - Used a **Decision Tree Regressor** for predictions.\n",
    "   - Employed **RandomizedSearchCV** to optimize hyperparameters, including:\n",
    "     - `max_depth`: Maximum depth of the tree.\n",
    "     - `min_samples_split`: Minimum samples required to split a node.\n",
    "     - `min_samples_leaf`: Minimum samples required to be at a leaf node.\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - **R²**: Coefficient of determination, indicating how well the model explains variance.\n",
    "   - **RMSE**: Root Mean Squared Error, measuring prediction accuracy.\n",
    "   - **MAE**: Mean Absolute Error, measuring average prediction error.\n",
    "\n",
    "4. **Visualizations**:\n",
    "   - Scatter plots comparing observed and predicted values.\n",
    "   - Residual analysis for error evaluation.\n",
    "   - Visualization of the trained Decision Tree for interpretability.\n",
    "\n",
    "## Data Processing Steps\n",
    "\n",
    "- **Handling Missing Data**: Missing values in the dataset were filled with the median of each column.\n",
    "- **Scaling**: Feature scaling was applied using Min-Max Scaling to normalize the input range.\n",
    "- **One-Hot Encoding**: Converted categorical columns into numerical columns using one-hot encoding.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "For each target variable (`size_nm`, `S_abs_nm_Y1`, `PL`), the following metrics were calculated:\n",
    "\n",
    "- **Train Data Performance**:\n",
    "  - R²\n",
    "  - RMSE\n",
    "  - MAE\n",
    "\n",
    "- **Test Data Performance**:\n",
    "  - R²\n",
    "  - RMSE\n",
    "  - MAE\n",
    "\n",
    "The results were stored in dictionaries and displayed for easy interpretation.\n",
    "\n",
    "## Code Summary\n",
    "\n",
    "The following Python packages were used:\n",
    "\n",
    "- `pandas` for data manipulation.\n",
    "- `scikit-learn` for machine learning and evaluation.\n",
    "- `matplotlib` and `seaborn` for visualizations.\n",
    "\n",
    "## Results and Insights\n",
    "\n",
    "- The Decision Tree model provides an interpretable structure for understanding feature contributions.\n",
    "- Residual plots help identify patterns in prediction errors, revealing potential areas for model improvement.\n",
    "- Hyperparameter tuning ensures the model achieves optimal performance for each target variable.\n",
    "\n",
    "## Decision Tree Visualization\n",
    "\n",
    "The tree structure reveals the hierarchy of feature splits, aiding in understanding the decision-making process of the model.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "file_path1 = \"/Users/mehmetsiddik/Desktop/Musa/modified_data.xlsx\"\n",
    "file_path2 = \"/Users/mehmetsiddik/Desktop/Musa/CsPbCl3_QDs.xlsx\"\n",
    "CsPbCl3 = pd.read_excel(file_path1)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = CsPbCl3.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(CsPbCl3[categorical_columns])\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names(categorical_columns))\n",
    "\n",
    "# Replace categorical columns with one-hot encoded columns\n",
    "CsPbCl3_encoded = CsPbCl3.drop(categorical_columns, axis=1)\n",
    "CsPbCl3_encoded = pd.concat([CsPbCl3_encoded, one_hot_encoded_df], axis=1)\n",
    "\n",
    "# Target variables\n",
    "targets = ['size_nm', 'S_abs_nm_Y1', 'PL']\n",
    "\n",
    "# Initialize dictionaries to store results and predictions\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "# Model training and evaluation for each target\n",
    "for target in targets:\n",
    "    print(f\"Evaluating target: {target}\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = CsPbCl3_encoded.drop(target, axis=1)\n",
    "    y = CsPbCl3_encoded[target]\n",
    "\n",
    "    # Fill missing values with the median\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Decision Tree Regressor with hyperparameter tuning\n",
    "    param_dist = {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    dtr = DecisionTreeRegressor(random_state=42)\n",
    "    random_search = RandomizedSearchCV(dtr, param_dist, cv=5, n_iter=10, random_state=42, verbose=1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    best_model = random_search.best_estimator_\n",
    "    predictions_train = best_model.predict(X_train)\n",
    "    predictions_test = best_model.predict(X_test)\n",
    "\n",
    "    # Store predictions\n",
    "    predictions[target] = {\n",
    "        'y_test': y_test,\n",
    "        'predictions_test': predictions_test\n",
    "    }\n",
    "\n",
    "    # Performance metrics\n",
    "    results[target] = {\n",
    "        'Train R2': r2_score(y_train, predictions_train),\n",
    "        'Test R2': r2_score(y_test, predictions_test),\n",
    "        'Train RMSE': np.sqrt(mean_squared_error(y_train, predictions_train)),\n",
    "        'Test RMSE': np.sqrt(mean_squared_error(y_test, predictions_test)),\n",
    "        'Train MAE': mean_absolute_error(y_train, predictions_train),\n",
    "        'Test MAE': mean_absolute_error(y_test, predictions_test)\n",
    "    }\n",
    "\n",
    "    # Print performance metrics\n",
    "    print(\"Performance for train data:\")\n",
    "    print(\"R2:\", r2_score(y_train, predictions_train))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, predictions_train)))\n",
    "    print(\"MAE:\", mean_absolute_error(y_train, predictions_train))\n",
    "\n",
    "    print(\"Performance for test data:\")\n",
    "    print(\"R2:\", r2_score(y_test, predictions_test))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, predictions_test)))\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, predictions_test))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display results\n",
    "print(results)\n",
    "\n",
    "# Plotting results\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "titles = ['Size (size_nm)', '1 S abs (S_abs_nm_Y1)', 'PL']\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    y_test = predictions[target]['y_test']\n",
    "    predictions_test = predictions[target]['predictions_test']\n",
    "\n",
    "    # Plot observed vs sample numbers\n",
    "    sns.scatterplot(\n",
    "        x=np.arange(1, len(y_test) + 1),\n",
    "        y=y_test.values,\n",
    "        ax=axs[i, 0],\n",
    "        label='Observed',\n",
    "        color='red'\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=np.arange(1, len(y_test) + 1),\n",
    "        y=predictions_test,\n",
    "        ax=axs[i, 0],\n",
    "        label='Predicted',\n",
    "        color='#4363d8'\n",
    "    )\n",
    "    axs[i, 0].set_title(f'{titles[i]} - Observed vs Predicted')\n",
    "    axs[i, 0].set_xlabel('Sample Number')\n",
    "    axs[i, 0].set_ylabel('Values (nm)')\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    # Plot observed vs predicted values\n",
    "    residuals = y_test.values - predictions_test\n",
    "    sns.scatterplot(\n",
    "        x=y_test.values,\n",
    "        y=predictions_test,\n",
    "        hue=residuals,\n",
    "        ax=axs[i, 1],\n",
    "        palette='coolwarm'\n",
    "    )\n",
    "    axs[i, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    axs[i, 1].set_title(f'{titles[i]} - Observed vs Predicted')\n",
    "    axs[i, 1].set_xlabel('Observed Values')\n",
    "    axs[i, 1].set_ylabel('Predicted Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot decision tree for the first target\n",
    "target = 'size_nm'\n",
    "X = CsPbCl3_encoded.drop(target, axis=1)\n",
    "y = CsPbCl3_encoded[target]\n",
    "\n",
    "# Train the model for visualization\n",
    "best_model.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(best_model, feature_names=X.columns, filled=True, rounded=True)\n",
    "plt.title(f'Decision Tree for {target}')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
